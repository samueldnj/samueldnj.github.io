[{"authors":null,"categories":null,"content":"  We made it a whole year! Our son just turned 1 year old!! We made it through the first year, with all its trials, twists and turns. We’re all happier, older, more full of love, and I hope a little bit wiser.\nTo celebrate, I’m going to prove how much of a nerdy PhDad I am. I’m going to spend my saturday night fitting growth models to his height and weight observations we took at the various doctors’ appointments last year, instead of working on my thesis or a talk I’m giving next week.\nReally, I’m interested in 2 things: (1) trying to fit the data with a model, and (2) trying to predict my son’s adult height. I’m envisioning this as a series of blog posts that I update with new data points. Ideally, I would be able to update my model fit as time goes on, and if this website persists long enough, I would be able to (in)validate my model with the true observations in about 18-22 years. Hah!\n Data First, we need the data. I used a handy phone app to record heights and weights whenever they were observed at the various appointments. These data have been collected into the table at the bottom of this post. This shows the observations of height and weight (if the were taken) on julian day \\(j\\) since his birthday (\\(j = 1\\)).\nWe can visualise the data on a multi-panel plot, and fit a smoother to each quantity to take a look at the average behaviour. I’ve done this below. Notice that we have a lot more weight observations than height observations in the first four months. All I can say about that is breastfeeding is HARD, and my wife is a rockstar. The other thing you might notice is that this data follows a fairly steady trend. The deviations in the height plots are likely observation errors (height data for infants is noisy). On the other hand, the deviations for weight observations are likely process variation, as doctors’ offices have fairly accurate scales that take an average weight over a time period; this variation can be explained by changes in my son’s diet and the occasional growth spurt.\n Modeling human growth There are several papers on modeling human growth in the medical literature that I just turned up in a quick google scholar search. Most are based on the Infancy-Childhood-Puberty (ICP) model (Karlberg 1987), which seems to have been the standard for most of the last 30 years. Recently, an updated approach was derived based on phenomenological universalities (Gliozzi et al. 2012), but to my untrained eye this model overlaps a lot with the ICP model.\nI’m going to use a different model, though. You might have guessed it, given that I’m a fisheries student, but I’m going to use a von Bertalanffy model, which I will refer to as the vonB model for short. This is because neither of the above models from the medical literature satisfy both of my requirements for this post. They’ll certainly fit to my son’s data (who knows how well - maybe another post) but they won’t predict adult height from infant observations given that they switch model structures for different life stages, so I’m going to pass on them.\nDefining the model I’m going to use the form of the vonB model that de-correlates the asymptotic (adult) length \\(L_{\\infty}\\) from the growth ‘rate’1 \\(K\\) (Schnute 1981; Francis 2016): \\[ L_a = L_1 + (L_2 - L_1) \\cdot \\frac{e^{-K A_1} - e^{-K a}}{e^{-K A_1} - e^{-K A_2}}. \\] Here, \\(L_a\\) is the length at age \\(a\\), in years, \\(K\\) is the rate of change in length per unit time, and \\(L_1\\) and \\(L_2\\) are the lengths at ages \\(A_1\\) and \\(A_2\\), ages that are chosen to be representative of early and late stage lengths, respectively.\nI’m going to have to modify this model a little bit to use the data I have. First, humans stand up, so I’m modeling height \\(H\\), not growth \\(L\\) - a completely aesthetic changes of variables. Second, I have observations with time-steps in days, not years, so I’m going to have to use a different rate \\(K\u0026#39; = K/365\\), making the formula \\[ H_d = H_1 + (H_2 - H_1) \\cdot \\frac{e^{-K\u0026#39; D_1} - e^{-K\u0026#39; d}}{e^{-K\u0026#39; D_1} - e^{-K\u0026#39; D_2}}, \\] where \\(D_1\\) and \\(D_2\\) are ages in days for \\(H_1\\) and \\(H_2\\), respectively.\nI should be able to estimate this model from the data, but I foresee at least one challenge. This is a three parameter model (\\(L_1\\), \\(L_2\\), and \\(K\\)). I technically have enough data to estimate three parameters, but I don’t have any data that represents the late stage height \\(H_2\\) (we’ve got some time to wait for that). I’m going to attempt extrapolating out to 18 years, by setting \\(D_2 = 365\\) to see what it does, and encouraging the model to 20 years by setting a prior distribution on the \\(K\\) parameter, with a mean value intended to produce something close to a heuristic prediction of adult height. My wife is 158 cm, and I am 178cm, so our son’s predicted maximum height according to this Mayo Clinic method is \\[ \\mu_{H_\\infty} = \\frac{158 + 178 + 13}{2} = 174.5 \\mbox{cm}. \\]\n  Implementing the vonB model R So, let’s get into the knitty-gritty. We’re going to optimise later, so I’m going to define a vonB() function, which takes the number of days \\(d\\) and the model parameters defined above as arguemnts. I’m going to set function default argument values based on the observations, with \\(D_1 = 100\\), \\(D_2 = 365\\), and assume a yearly \\(K = 0.25\\) for now.\n# First, create a function to calculate the # height at a given day d. Leading parameters # H_1, H_2 and K are separated from D values # as pars are estimated model parameters passed # in from the log-likelihood function vonB \u0026lt;- function( d = 1, pars = c( H_1 = 62.5, H_2 = 74.5, K = 0.25 ), D = c(100,365) ) { # Recover pars H_1 \u0026lt;- pars[1] H_2 \u0026lt;- pars[2] K \u0026lt;- pars[3]/365 # Recover D values D_1 \u0026lt;- D[1] D_2 \u0026lt;- D[2] # Run calculation H_d \u0026lt;- H_1 + (H_2 - H_1) * (exp(-K*D_1) - exp(-K*d)) /( exp(-K*D_1) - exp(-K*D_2) ) # Return H_d return(H_d) } Fitting by eye If I run the model with the default values, we can see that it fits the data we have pretty well by eye. The only caveat is that the asymptotic height is 134.79cm, which is low based on my heuristic estimate of 174.5cm above. This is likely because my randomly chosen initial \\(K\\) value is too high, leading the growth to saturate at a lower asymptotic height.\nThanks to my functional workflow, it’s easy to change values and produce more growth curves.\nH2 \u0026lt;- vonB( d = 1:14600, pars = c( H_1 = 62.5, H_2 = 74.5, K = 0.16 ) ) Hinf2 \u0026lt;- max(H2) After some fiddling around, I can get a better asymptotic height from \\(K = 0.16\\), which produces an asymptotic height of 171.73cm. I’ve plotted this new curve and the previous model on the axes below.\n Optimisation Let’s optimise! First, we need a negative log-posterior density function, which we’re going to use in an optim() call. We’ll run the optimisation with the default values, which is a short interval between \\(D_1 = 100\\) and \\(D_2 = 365\\). I’m going to add three prior distributions to penalise deviations from (1) the last observed height of 74.5cm at 1 year old, (2) the \\(K = 0.16\\) growth rate that I eye-balled to give an adult height similar to the heuristic from the Mayo Clinic, and (3) an improper Jeffreys prior on the observation error \\(\\sigma\\).\nAssuming the residuals between the model and the data are normally distributed, we have the likelihood function \\[ \\mathcal{L} = \\prod_{i} \\frac{1}{2\\sqrt{\\pi\\sigma^2}} e^{-\\frac{(H_d - \\hat{H}_d)^2}{2\\sigma^2}}. \\] This is implemented in the following code chunk, along with the priors on \\(H_2\\), \\(K\\), and \\(\\sigma\\).\n# Define negative log posterior function, # we\u0026#39;re going to model the H1, H2 and K # values on the log scale, and we need to # model vonB_negLogPost \u0026lt;- function( theta = c( logH_1 = log(62.5), logH_2 = log(74.5), logK = log(0.16), logsigma = 0 ), data = growthData, D = c(100,365), H2Prior = c(74.5, 74.5), KPrior = c(.16, .16/2) ) { # Exponentiate leading pars of vonB pars \u0026lt;- c( H_1 = exp(theta[1]), H_2 = exp(theta[2]), K = exp(theta[3]) ) # uncertainty in the observations sigma \u0026lt;- exp(theta[\u0026quot;logsigma\u0026quot;]) # Calculate expected observations in a new column # of the data frame, then residuals, # and then the negative-log-likelihood (with # normalising scalar omitted) data \u0026lt;- data %\u0026gt;% mutate( expHeight = vonB(j, pars = pars, D = D), resid = expHeight - height, negloglik = 0.5*log(sigma^2) + 0.5 * resid^2/sigma^2 ) # Calculate observation NLL and H2/K neg log priors nll \u0026lt;- sum(data$negloglik, na.rm = T) nlp_H2 \u0026lt;- 0 nlp_K \u0026lt;- 0 # Only calculate priors if parameters are given if(!is.null(H2Prior)) nlp_H2 \u0026lt;- 0.5 * (pars[2] - H2Prior[1])^2/H2Prior[2]^2 if(!is.null(KPrior)) nlp_K \u0026lt;- 0.5 * (pars[3] - KPrior[1])^2/KPrior[2]^2 objFun \u0026lt;- nll + nlp_H2 + nlp_K + 10 * log(sigma) return(objFun) } I’m going to fit using optim() as my optimiser, with the Nelder-Mead optimisation method. The Nelder-Mead method is a direct-search method, as opposed to more common quasi-Newton methods of optimisation (see Wikipedia), which basically means that it uses the value of the objective function only, and no derivatives of the objective function. This makes it a little more robust to certain objective functions, albeit somewhat slower. I chose this because I have no need of the covariance matrix as an output (for now), which is one of the drawbacks of Nelder-Mead.\n# Fit with no priors fit1 \u0026lt;- optim( par = c( logH_1 = log(62.5), logH_2 = log(74.5), logK = log(0.16/365), logsigma = 0), fn = vonB_negLogPost, D = c(100,365), data = growthData, H2Prior = NULL, KPrior = NULL, method = \u0026quot;Nelder-Mead\u0026quot; ) # Fit with priors on K fit2 \u0026lt;- optim( par = c( logH_1 = log(62.5), logH_2 = log(74.5), logK = log(0.16/365), logsigma = 0), fn = vonB_negLogPost, D = c(100,365), data = growthData, H2Prior = NULL, KPrior = c(0.16,0.08), method = \u0026quot;Nelder-Mead\u0026quot; ) The parameters of the two models are given in the following table, and the plots are shown below that. We can see that the largest\n Table 1: Optimised parameters, adult height and negativ log-posterior values under both models.     \\[H_1\\]  \\[H_2\\]  \\[K\\]  \\[\\sigma\\]  \\[H_\\infty\\]  -log(Post)      No Priors  61.96  75.81  0.57  0.85  102.83  6.363659    Priors  62.26  76.71  0.18  0.95  180.12  8.692054     The model with no priors shows an adult (asymptotic) height of \\(H_\\infty = 102.83\\), meaning that my son is forecast by this model to be a little bit over 1 metre tall. Looking at the graph, we can see that he’s going to reach that height at about 2000 days, or 5.5 years old, influenced by a growth rate parameter of \\(K = 0.57\\). Given that both my wife and I are taller than this, and we know of no reasons why we would expect him to be under the first percentile for height, I don’t fully believe this model. On the other hand, we have the model with priors predicting my son will reach his adult height of \\(H_\\infty = 180.12\\) at about 20 years of age, with a much lower growth rate \\(K = 0.18\\). Although the second model is guided by subjective prior distributions, I believe it more - not only because it’s almost exactly my height, but also because aside from the value of \\(K\\) the model parameters are very close, and the negative-log-posterior values are also very close.\n  Conclusion  Table 2: Data for my son’s health visits.    j  height  weight      1  56.0  3.8    3    3.5    4    3.4    15    4.0    18    4.1    25    4.1    29    4.3    39    4.9    46    5.0    50  59.0      59    5.1    74    5.3    81  60.5  5.4    86  60.5  5.6    101  62.5  5.9    122  64.0  6.0    192  68.0  7.0    276  74.5  8.3    296  71.5  8.5    373  74.5  9.6                So, there we go. I fit a von Bertalanffy growth model to height observations from my son’s health appointments over the first year of his life (data to the right). My aim was to (1) see how well human growth data fit the vonB mode, and (2) predict his adult height from observations now. I found that the vonB model fits human growth data very well, at least during the first year of life where a single growth regime is present (Karlberg 1987). On the other hand, I found extrapolating beyond the first year problematic, and required subjective prior distributions on leading parameters to achieve a sensible height prediction.\nThe high growth rate of infants is likely the reason that the model without priors estimates a high \\(K\\) value, reaching \\(H_\\infty\\) sometime during childhood. According to the ICP model, infants have a high but rapidly decreasing growth rate, which is replaced by a lower, more stable, rate in childhood, and another different rate during puberty, before adult height is reached (Karlberg 1987). Later stages have a “humpy” growth pattern, where humps correspond to growth spurts during childhood and puberty.\nFurther work could be conducted to generate uncertainty in my prediction. I used a penalised likelihood method to estimate the parameters of the vonB model, with prior distributions penalising deviations from the observed height at 1 year old, and deviations from a growth rate that would produce an adult height that was similar to a weighted average of my wife’s and my own heights. Parameter estimates and the forecast are all maximum likelihood estimates (posterior modes), with no uncertainty reported. Confidence intervals could be estimated by using the delta-method, bootstrapping the residuals on each observation, or by running a Markov-Chain Monte-Carlo numerical integration of the posterior to generate full posterior distributions of all parameters and the model.\nThat’s all from me. Happy birthday to my son, thanks to my wife for growing him and being an awesome partner, and thanks to you for reading this nerdy Dad rant!\n References Francis, RIC Chris. 2016. “Growth in Age-Structured Stock Assessment Models.” Fisheries Research 180. Elsevier: 77–86.\n Gliozzi, Antonio S, Caterina Guiot, Pier Paolo Delsanto, and Dan A Iordache. 2012. “A Novel Approach to the Analysis of Human Growth.” Theoretical Biology and Medical Modelling 9 (1). BioMed Central: 17.\n Karlberg, Johan. 1987. “On the Modelling of Human Growth.” Statistics in Medicine 6 (2). Wiley Online Library: 185–92.\n Schnute, Jon. 1981. “A Versatile Growth Model with Statistically Stable Parameters.” Canadian Journal of Fisheries and Aquatic Sciences 38 (9). NRC Research Press: 1128–40.\n    yes, I know it’s not technically a rate↩\n   ","date":1547251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547251200,"objectID":"522c929e9ffcae74772548c7b7cc8ff7","permalink":"/post/baby-growth/baby-growth/","publishdate":"2019-01-12T00:00:00Z","relpermalink":"/post/baby-growth/baby-growth/","section":"post","summary":"We made it a whole year! Our son just turned 1 year old!! We made it through the first year, with all its trials, twists and turns. We’re all happier, older, more full of love, and I hope a little bit wiser.\nTo celebrate, I’m going to prove how much of a nerdy PhDad I am. I’m going to spend my saturday night fitting growth models to his height and weight observations we took at the various doctors’ appointments last year, instead of working on my thesis or a talk I’m giving next week.","tags":null,"title":"Estimating a von Bertalanffy growth model from height measurements of my son during his first year of life","type":"post"},{"authors":null,"categories":null,"content":" Download a PDF copy.\nEmployment  2016 - Present: Sub-contracting Consultant Landmark Fisheries Research (Port Moody, BC) Supervisors: Ashleen Benson, Sean Cox 2016 - Present: MITACS Accelerate Intern Wild Canadian Sablefish (Steveston, BC) Pacific Halibut Management Association (Vancouver, BC) Canadian Groundfish Research and Conservation Society (New Westminster, BC) Supervisors: Sean Cox, Chris Acheson, Chris Sporer, Bruce Turris 2015 - 2016: MITACS Accelerate Intern Wild Canadian Sablefish (Steveston, BC) Supervisors: Sean Cox, Chris Acheson 2012 - 2014: Research Assistant Department of Mathematics, Simon Fraser University (Burnaby, BC) Supervisor: Marni Mishna  Education  2014 - 2019 (Expected) PhD, Resource and Environmental Management Simon Fraser University (Burnaby, BC) Advisor: Associate Professor Sean Cox Thesis title: Multispecies Management Tools for Multi Sector Fisheries 2010 - 2012: MSc, Mathematics Simon Fraser University (Burnaby, BC) Advisor: Associate Professor Marni Mishna Thesis title: Analytic Combinatorics of Planar Lattice Paths 2005-2009: B. Mathematics (Hons) University of Newcastle (Newcastle, NSW) Honours Advisor: Associate Professor George Willis Honours Thesis Title: Simple Groups of Automorphisms of Locally Finite Trees  Technical Skills  I am proficient in the R statistical language, Rmarkdown, latex, Auto-Differentiation Model Builder (ADMB), and Template Model Builder (TMB) I have used SQL, Python, and C++ I\u0026rsquo;ve conducted closed loop simulations in a management strategy evaluation (MSE) framework for simulated and real fishery management systems, including Northern Cod (Gadus morhua) in Atlantic Canada, and Sablefish (Anoplopoma fimbria) and Herring (Clupea pallasii) in Pacific Canada I\u0026rsquo;m experienced in teaching technical material in both small and large classroom settings  Publications ","date":1547107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547107200,"objectID":"7e6115c4d209379befeb3847e8c4905b","permalink":"/cv/","publishdate":"2019-01-10T00:00:00-08:00","relpermalink":"/cv/","section":"","summary":"Download a PDF copy.\nEmployment  2016 - Present: Sub-contracting Consultant Landmark Fisheries Research (Port Moody, BC) Supervisors: Ashleen Benson, Sean Cox 2016 - Present: MITACS Accelerate Intern Wild Canadian Sablefish (Steveston, BC) Pacific Halibut Management Association (Vancouver, BC) Canadian Groundfish Research and Conservation Society (New Westminster, BC) Supervisors: Sean Cox, Chris Acheson, Chris Sporer, Bruce Turris 2015 - 2016: MITACS Accelerate Intern Wild Canadian Sablefish (Steveston, BC) Supervisors: Sean Cox, Chris Acheson 2012 - 2014: Research Assistant Department of Mathematics, Simon Fraser University (Burnaby, BC) Supervisor: Marni Mishna  Education  2014 - 2019 (Expected) PhD, Resource and Environmental Management Simon Fraser University (Burnaby, BC) Advisor: Associate Professor Sean Cox Thesis title: Multispecies Management Tools for Multi Sector Fisheries 2010 - 2012: MSc, Mathematics Simon Fraser University (Burnaby, BC) Advisor: Associate Professor Marni Mishna Thesis title: Analytic Combinatorics of Planar Lattice Paths 2005-2009: B.","tags":null,"title":"Curriculum Vitae","type":"page"},{"authors":null,"categories":null,"content":" Download a PDF copy.\nEmployment  2016 - Present: Sub-contracting Consultant Landmark Fisheries Research (Port Moody, BC) Supervisors: Ashleen Benson, Sean Cox 2016 - Present: MITACS Accelerate Intern Wild Canadian Sablefish (Steveston, BC) Pacific Halibut Management Association (Vancouver, BC) Canadian Groundfish Research and Conservation Society (New Westminster, BC) Supervisors: Sean Cox, Chris Acheson, Chris Sporer, Bruce Turris 2015 - 2016: MITACS Accelerate Intern Wild Canadian Sablefish (Steveston, BC) Supervisors: Sean Cox, Chris Acheson 2012 - 2014: Research Assistant Department of Mathematics, Simon Fraser University (Burnaby, BC) Supervisor: Marni Mishna  Education  2014 - 2019 (Expected) PhD, Resource and Environmental Management Simon Fraser University (Burnaby, BC) Advisor: Associate Professor Sean Cox Thesis title: Multispecies Management Tools for Multi Sector Fisheries 2010 - 2012: MSc, Mathematics Simon Fraser University (Burnaby, BC) Advisor: Associate Professor Marni Mishna Thesis title: Analytic Combinatorics of Planar Lattice Paths 2005-2009: B. Mathematics (Hons) University of Newcastle (Newcastle, NSW) Honours Advisor: Associate Professor George Willis Honours Thesis Title: Simple Groups of Automorphisms of Locally Finite Trees  Technical Skills  I\u0026rsquo;m proficient in the R statistical language, Auto-Differentiation Model Builder (ADMB) and Python I\u0026rsquo;ve conducted closed loop simulations in a management strategy evaluation (MSE) framework for simulated and real fishery management systems, including Northern Cod (Gadus morhua) in Atlantic Canada, and Sablefish (Anoplopoma fimbria) and Herring (Clupea pallasii) in Pacific Canada I\u0026rsquo;m experienced in teaching technical material in both small and large classroom settings  ","date":1547078400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547078400,"objectID":"8303249760bb5b86ecf00e59fe3c87ea","permalink":"/cv2/","publishdate":"2019-01-10T00:00:00Z","relpermalink":"/cv2/","section":"","summary":"Download a PDF copy.\nEmployment  2016 - Present: Sub-contracting Consultant Landmark Fisheries Research (Port Moody, BC) Supervisors: Ashleen Benson, Sean Cox 2016 - Present: MITACS Accelerate Intern Wild Canadian Sablefish (Steveston, BC) Pacific Halibut Management Association (Vancouver, BC) Canadian Groundfish Research and Conservation Society (New Westminster, BC) Supervisors: Sean Cox, Chris Acheson, Chris Sporer, Bruce Turris 2015 - 2016: MITACS Accelerate Intern Wild Canadian Sablefish (Steveston, BC) Supervisors: Sean Cox, Chris Acheson 2012 - 2014: Research Assistant Department of Mathematics, Simon Fraser University (Burnaby, BC) Supervisor: Marni Mishna  Education  2014 - 2019 (Expected) PhD, Resource and Environmental Management Simon Fraser University (Burnaby, BC) Advisor: Associate Professor Sean Cox Thesis title: Multispecies Management Tools for Multi Sector Fisheries 2010 - 2012: MSc, Mathematics Simon Fraser University (Burnaby, BC) Advisor: Associate Professor Marni Mishna Thesis title: Analytic Combinatorics of Planar Lattice Paths 2005-2009: B.","tags":null,"title":"Curriculum Vitae","type":"page"},{"authors":["Samuel Johnson","Marni Mishna","Karen Yeats"],"categories":null,"content":"","date":1545025834,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545025834,"objectID":"907f215ef7f743a6493fd3bdfeadbf77","permalink":"/publication/latticepathasymptotics/","publishdate":"2018-12-16T21:50:34-08:00","relpermalink":"/publication/latticepathasymptotics/","section":"publication","summary":"We provide a combinatorial derivation of the exponential growth constant for counting sequences of lattice path models restricted to the quarter plane. The values arise as bounds from analysis of related half planes models. We give explicit formulas, and the bounds are provably tight. The strategy is easily generalizable to cones in higher dimensions, and has implications for random generation.","tags":[],"title":"A combinatorial understanding of lattice path asymptotics.","type":"publication"},{"authors":["Beau Doherty","Samuel D N Johnson","Sean P Cox"],"categories":null,"content":"","date":1545025824,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545025824,"objectID":"f8c1d73c91679fd6a98e701aad1036e5","permalink":"/publication/bottomcontact/","publishdate":"2018-12-16T21:50:24-08:00","relpermalink":"/publication/bottomcontact/","section":"publication","summary":"Bottom longline hook and trap fishing gear can potentially damage sensitive benthic areas (SBAs) in the ocean; however, the large-scale risks to these habitats are poorly understood because of the difficulties in mapping SBAs and in measuring the bottom-contact area of longline gear. In this paper, we describe a collaborative academic–industry–government approach to obtaining direct presence–absence data for SBAs and to measuring gear interactions with seafloor habitats via a novel deepwater trap camera and motion-sensing systems on commercial longline traps for sablefish (Anoplopoma fimbria) within SGaan Kinghlas – Bowie Seamount Marine Protected Area. We obtained direct presence–absence observations of cold-water corals (Alcyonacea, Antipatharia, Pennatulacea, Stylasteridae) and sponges (Hexactinellida, Demospongiae) at 92 locations over three commercial fishing trips. Video, accelerometer, and depth sensor data were used to estimate a mean bottom footprint of 53 m2 for a standard sablefish trap, which translates to 3200 m2 (95% CI = 2400–3900 m2) for a 60-trap commercial sablefish longline set. Our successful collaboration demonstrates how research partnerships with commercial fisheries have potential for massive improvements in the quantity and quality of data needed for conducting SBA risk assessments over large spatial and temporal scales","tags":[],"title":"Using autonomous video to estimate the bottom-contact area of longline trap gear and presence–absence of sensitive benthic habitat","type":"publication"},{"authors":null,"categories":null,"content":" This is version 3 of my personal website. I’ve revised to a Hugo powered blogdown generated website for two reasons. First, it’s a static site generator, similar to Jekyll, serving to keep things simple and fast on the server side. Second, I’ve wanted to start blogging more, and I think the Rmarkdown integration with blogdown and Hugo will help smooth this out.\nThis post is a test post for using Rmarkdown to build a simple population dynamics model with process error, and generate some data with observation error. Pushing this post to github pages will require working out how TravisCI works, which I learned from David Selby’s Tea and Stats blog - a handy resource.\nSo, let’s get started by defining a function for the population dynamics model. I’m going to use a Schaefer surplus production model (Schaefer 1957). I like to define my Schafer models using optimal equilibrium values, known as \\(B_{MSY}\\) and \\(U_{MSY}\\) in the fisheries literature, as the leading parameters.\nset.seed(123) # Create a function to quickly call for generating biomass prodMod \u0026lt;- function( Umsy = 0.06, Bmsy = 42, procSigma = 0.1, obsSigma = 0.2, nT = 100 ) { # Vectors to hold biomass and catch Bt \u0026lt;- numeric( length = nT ) Ct \u0026lt;- numeric( length = nT ) # Create a sequence of harvest rates Utmult \u0026lt;- c(seq(0.1,2,length = 20),seq(2,1, length = 20), rep(1,nT - 40) ) Ut \u0026lt;- Utmult * Umsy # And draw process errors epst \u0026lt;- rnorm(nT-1, sd = procSigma) # Initialise at unfished Bt[1] \u0026lt;- 2 * Bmsy # Take first year\u0026#39;s catch Ct[1] \u0026lt;- Ut[1] * Bt[1] # Now loop and fill remaining years for( t in 2:nT ) { # Generate non-stochastic biomass Bt[t] \u0026lt;- Bt[t-1] + 2 * Umsy * Bt[t-1] * (1 - Bt[t-1] / Bmsy / 2) - Ct[t-1] # Add process errors Bt[t] \u0026lt;- Bt[t] * exp( epst[t-1]) # Take catch Ct[t] \u0026lt;- Bt[t] * Ut[t] } # Draw observation errors deltat \u0026lt;- rnorm(nT, sd = obsSigma) # Generate absolute index of biomass It \u0026lt;- Bt * exp(deltat) # Return biomass, catch and model time dimension outList \u0026lt;- list( Bt = Bt, It = It, Ct = Ct, nT = nT ) } # Generate the biomass popSP \u0026lt;- prodMod() # Plot the biomass and catch plot( x = 1:popSP$nT, y = popSP$Bt, xlab = \u0026quot;Year\u0026quot;, ylab = \u0026quot;Biomass and Catch\u0026quot;, ylim = c(0,max(popSP$Bt)), type = \u0026quot;l\u0026quot;, col = \u0026quot;red\u0026quot;, lwd = 2, las = 1 ) rect( xleft = 1:popSP$nT-.3, xright = 1:popSP$nT + .3, ybottom = 0, ytop = popSP$Ct, col = \u0026quot;grey40\u0026quot;, border = NA ) points( x = 1:popSP$nT, y = popSP$It, pch = 21, col = \u0026quot;grey60\u0026quot;, cex = .8 ) Our figure shows a 2-way trip, which describes how the biomass declines at first (the first way), then comes back up as catch is decreased (the second way). This is an ideal data set for fisheries stock assessment, as there is contrast in the catch and biomass, making it informative about both the scale of the biomass, helping to estimate \\(B_{MSY}\\), and the productivity of the stock, helping to estimate \\(U_{MSY}\\).\nThe next part of this post will fit a TMB model to the data generated from the above biomass. I ran this same tutorial in a seminar for our lab group at SFU this past fall, so I’ll be copying and pasting the code in from there.\nSchaefer, Milner B. 1957. “Some Considerations of Population Dynamics and Economics in Relation to the Management of the Commercial Marine Fisheries.” Journal of the Fisheries Board of Canada 14 (5). NRC Research Press: 669–81.\n  ","date":1545004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545004800,"objectID":"e9dde6a7588df5f5fc7fa93db174c8a7","permalink":"/post/test-rmd/test-rmd/","publishdate":"2018-12-17T00:00:00Z","relpermalink":"/post/test-rmd/test-rmd/","section":"post","summary":"This is version 3 of my personal website. I’ve revised to a Hugo powered blogdown generated website for two reasons. First, it’s a static site generator, similar to Jekyll, serving to keep things simple and fast on the server side. Second, I’ve wanted to start blogging more, and I think the Rmarkdown integration with blogdown and Hugo will help smooth this out.\nThis post is a test post for using Rmarkdown to build a simple population dynamics model with process error, and generate some data with observation error.","tags":null,"title":"Testing Rmd Support using a Schafer model","type":"post"},{"authors":null,"categories":null,"content":" First Post! Welcome to my blog! I plan to use this blog for two main purposes. The first is as an academic learning resource, where I will write posts that go through new concepts that I\u0026rsquo;m interested in learning about. The second is to develop new research ideas, with a view to refining them into primary publications.\nMost posts will have something to do with Fisheries Science, the field I\u0026rsquo;m actively involved in. Fisheries science is an applied discipline drawing on the fields of biology, population ecology, statistics, data science, decision analysis, and risk assessment just to name a few. I specialise in fisheries stock assessment modeling, which is the application of population dynamics for the determination of fish stock status. I am also interested in broadening my understanding of ecological theory and new applied tools for testing hypotheses, and improving my science communication skills through better writing, data visualisation.\nThanks for visiting, and be sure to return for future posts with some more theoretical exposition.\n","date":1544947200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1544947200,"objectID":"aea8e115492523ac7785e9116e94fe3e","permalink":"/post/first-post/first-post/","publishdate":"2018-12-16T00:00:00-08:00","relpermalink":"/post/first-post/first-post/","section":"post","summary":"First Post! Welcome to my blog! I plan to use this blog for two main purposes. The first is as an academic learning resource, where I will write posts that go through new concepts that I\u0026rsquo;m interested in learning about. The second is to develop new research ideas, with a view to refining them into primary publications.\nMost posts will have something to do with Fisheries Science, the field I\u0026rsquo;m actively involved in.","tags":null,"title":"Welcome!","type":"post"},{"authors":["Samuel D N Johnson","Sean P Cox"],"categories":null,"content":"","date":1539927984,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539927984,"objectID":"52dccb01e4df82cbd629f99021c0cc8d","permalink":"/publication/hierprod/","publishdate":"2018-10-18T21:46:24-08:00","relpermalink":"/publication/hierprod/","section":"publication","summary":"An emerging approach to data-limited fisheries stock assessment uses hierarchical multi-stock assessment models to group stocks together, sharing information from data-rich to data-poor stocks. In this paper, we simulate data-rich and data-poor fishery and survey data scenarios for a complex of dover sole stocks. Simulated data for individual stocks were used to compare estimation performance for single-stock and hierarchical multi-stock versions of a Schaefer production model. The single-stock and best performing multi-stock models were then used in stock assessments for the real dover sole data. Multi-stock models often had lower estimation errors than single-stock models when assessment data had low statistical power. Relative errors for productivity and relative biomass parameters were lower for multi-stock assessment model configurations. In addition, multi-stock models that estimated hierarchical priors for survey catchability performed the best under data-poor scenarios. We conclude that hierarchical multi-stock assessment models are useful for data-limited stocks and could provide a more flexible alternative to data-pooling and catch only methods; however, these models are subject to non-linear side-effects of parameter shrinkage. Therefore, we recommend testing hierarchical multi-stock models in closed-loop simulations before application to real fishery management systems.","tags":[],"title":"Evaluating the role of data quality when sharing information in hierarchical multi-stock assessment models, with an application to Dover Sole.","type":"publication"}]